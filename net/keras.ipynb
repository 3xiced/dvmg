{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataSet\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "onlyfiles = [f for f in listdir(\"../dataset/\") if isfile(join(\"../dataset/\", f))]\n",
    "\n",
    "def parse(path: str, pattern_name: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Парсит уже существующие JSON файл и сортирует координаты в случайном порядке для обучения\n",
    "    нейронной сети.  \n",
    "\n",
    "    Args:\n",
    "        path (str): путь до JSON файла\n",
    "        pattern_name (str): название паттерна, который будет верным в обучении\n",
    "    Returns:\n",
    "        tuple(np.ndarray, np.ndarray): Кортеж из значений на вход (X) и соответствующие им значения корректности\n",
    "    \"\"\"\n",
    "    _X = np.empty((0, 14), int) # Данные для обучения (координаты реконструкции фазового портрета) до сортировки\n",
    "    _y = np.array([]) # 1 - соответствует правильному паттерну, на который тренируется сеть, 0 - всем остальным до сортировки\n",
    "    random_value = np.array([]) # Случайная величина для перемешивания датасета\n",
    "    with open(path, 'r') as json_file:\n",
    "        data: dict = json.load(json_file)\n",
    "        \n",
    "        for ptrn in list(data.keys()):\n",
    "            all_coordinates: list = data[ptrn]\n",
    "            \n",
    "            for local_cordinates in all_coordinates:\n",
    "                _X = np.append(_X, np.array([np.append(np.array(local_cordinates['x']), np.array(local_cordinates['y'])).tolist()]), axis=0)\n",
    "                _y = np.append(_y, 1) if ptrn == pattern_name else np.append(_y, 0)\n",
    "                random_value = np.append(random_value, np.random.rand()) # Генерация случайного числа от 0 до 1\n",
    "\n",
    "    # Сортировка по случайным величинам\n",
    "    return (np.array([x for _, x, _ in sorted(zip(random_value, _X, _y), key=lambda x: x[0])]),\n",
    "            np.array([y for _, _, y in sorted(zip(random_value, _X, _y), key=lambda x: x[0])]))\n",
    "\n",
    "dataset: list[tuple[tuple, tuple, str]] = list()\n",
    "\n",
    "training_file_path = '../dataset/26136163268846ea912ade4c2d2b4e5f.json'\n",
    "test_file_path = '../dataset/e9f2619a28054ec6a081e0bb30822271.json'\n",
    "\n",
    "patterns = ['Sigmoid', 'SigmoidReversed', 'Normal', 'NormalFlipped', 'Plain', 'LinearIncrease', 'LinearDecrease']\n",
    "\n",
    "for ptrn in patterns:\n",
    "\n",
    "    pattern_name = ptrn\n",
    "    X, y = parse(training_file_path, pattern_name)\n",
    "    test_data_X, test_data_y = parse(test_file_path, pattern_name)\n",
    "\n",
    "    dataset += [((X,y),(test_data_X,test_data_y), pattern_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "0.7324285714285714 - Sigmoid\n",
      "0.8570476190476191 - SigmoidReversed\n",
      "0.8461428571428572 - Normal\n",
      "0.7963333333333333 - NormalFlipped\n",
      "0.7811428571428571 - Plain\n",
      "0.7669047619047619 - LinearIncrease\n",
      "0.6849047619047619 - LinearDecrease\n",
      "-------------------------\n",
      "0.7273333333333334 - Sigmoid\n",
      "0.8554761904761905 - SigmoidReversed\n",
      "0.8 - Normal\n",
      "0.8431904761904762 - NormalFlipped\n",
      "0.7639523809523809 - Plain\n",
      "0.7161428571428572 - LinearIncrease\n",
      "0.6938095238095238 - LinearDecrease\n",
      "-------------------------\n",
      "0.7413333333333333 - Sigmoid\n",
      "0.8555714285714285 - SigmoidReversed\n",
      "0.785047619047619 - Normal\n",
      "0.8273333333333334 - NormalFlipped\n",
      "0.8485238095238096 - Plain\n",
      "0.8565238095238096 - LinearIncrease\n",
      "0.7462380952380953 - LinearDecrease\n",
      "-------------------------\n",
      "0.7276190476190476 - Sigmoid\n",
      "0.8569523809523809 - SigmoidReversed\n",
      "0.8047619047619048 - Normal\n",
      "0.8560476190476191 - NormalFlipped\n",
      "0.7007142857142857 - Plain\n",
      "0.8569523809523809 - LinearIncrease\n",
      "0.6863809523809524 - LinearDecrease\n",
      "-------------------------\n",
      "0.740904761904762 - Sigmoid\n",
      "0.8560952380952381 - SigmoidReversed\n",
      "0.8149047619047619 - Normal\n",
      "0.8463809523809523 - NormalFlipped\n",
      "0.8466190476190476 - Plain\n",
      "0.7142857142857143 - LinearIncrease\n",
      "0.7446190476190476 - LinearDecrease\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, lr=0.01, epochs=5):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Our fit function trains on the dataset X and tries to predict vector y,\n",
    "        Using the learning rate, it will modify it's weight vector to increase\n",
    "        it's accuracy in predictions.\n",
    "        It will iterate over the X dataset as defined by the epochs.\n",
    "        Args:\n",
    "            X: The input data (numpy array of shape [n_samples * m_features])\n",
    "            y: Class labels vector (numpy array of shape [n_samples])\n",
    "        \"\"\"\n",
    "        # a vector of floats between 0 and 1\n",
    "        weights = np.random.rand(X.shape[1],)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # list of predicted classes for our accuracy calculation\n",
    "            predicted = []\n",
    "            for i_index, sample in enumerate(X):\n",
    "                y_hat = self.predict(sample, weights)\n",
    "                predicted.append(y_hat)  # add our new prediction to the array\n",
    "                for j_index, feature in enumerate(weights):\n",
    "                    # update our weight values\n",
    "                    delta = self.lr * (y[i_index] - y_hat)\n",
    "                    delta = delta * sample[j_index-1]\n",
    "                    weights[j_index-1] = weights[j_index-1] + delta\n",
    "            # print('[Epoch {ep}] Accuracy: {acc}'.format(\n",
    "            #     ep=epoch, acc=self._calculate_accuracy(y, predicted)\n",
    "            # ))\n",
    "        self.weights = weights\n",
    "\n",
    "    def _calculate_accuracy(self, actual, predicted):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of predictions for this epoch.\n",
    "        Args:\n",
    "            actual: vector of actual class values (the y vector) [n_samples]\n",
    "            predicted: vector of predicted class values [n_samples]\n",
    "        \"\"\"\n",
    "        return sum(np.array(predicted) == np.array(actual)) / float(len(actual))\n",
    "\n",
    "    def predict(self, x, w):\n",
    "        \"\"\"\n",
    "        Create a binary prediction from an activation function on the data\n",
    "        sample and the weight vector.\n",
    "        Args:\n",
    "            x: vector of the data sample - shape [m_features]\n",
    "            w: vector of the weights - shape [m_features]\n",
    "        Returns:\n",
    "            0 or 1\n",
    "        \"\"\"\n",
    "        res = self._sum(x, w)\n",
    "        # print(res)\n",
    "        return 1 if res > 0.0 else 0.0\n",
    "\n",
    "    def _sum(self, x, w):\n",
    "        \"\"\"\n",
    "        Multiply our sample and weight vector elements then the sum of the\n",
    "        result.\n",
    "        Args:\n",
    "            x: vector of the data sample - shape [m_features]\n",
    "            w: vector of the weights - shape [m_features]\n",
    "        Returns:\n",
    "            Int of the sum of vector products\n",
    "        \"\"\"\n",
    "        return np.sum(np.dot(x, np.transpose(w)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in range(5):\n",
    "        print('-------------------------')\n",
    "        for data in dataset:\n",
    "            (_X,_y), (_test_data_X, _test_data_y), name = data\n",
    "            p = Perceptron()\n",
    "\n",
    "            # Train\n",
    "            p.fit(_X, _y)\n",
    "            truth = 0\n",
    "            for i in range(len(_test_data_X)):\n",
    "                prd = p.predict(_test_data_X[i],p.weights)\n",
    "                if prd == y[i]:\n",
    "                    truth += 1\n",
    "            print(str(truth/len(y)) + ' - '+ name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5102983151a502f0b3c21dd441eb79f35619ea9e057c95bc886ff9f2b76b13c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
