{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataSet\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "onlyfiles = [f for f in listdir(\"../dataset/\") if isfile(join(\"../dataset/\", f))]\n",
    "\n",
    "def parse(path: str, pattern_name: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Парсит уже существующие JSON файл и сортирует координаты в случайном порядке для обучения\n",
    "    нейронной сети.  \n",
    "\n",
    "    Args:\n",
    "        path (str): путь до JSON файла\n",
    "        pattern_name (str): название паттерна, который будет верным в обучении\n",
    "    Returns:\n",
    "        tuple(np.ndarray, np.ndarray): Кортеж из значений на вход (X) и соответствующие им значения корректности\n",
    "    \"\"\"\n",
    "    _X = np.empty((0, 14), int) # Данные для обучения (координаты реконструкции фазового портрета) до сортировки\n",
    "    _y = np.array([]) # 1 - соответствует правильному паттерну, на который тренируется сеть, 0 - всем остальным до сортировки\n",
    "    random_value = np.array([]) # Случайная величина для перемешивания датасета\n",
    "    with open(path, 'r') as json_file:\n",
    "        data: dict = json.load(json_file)\n",
    "        \n",
    "        for ptrn in list(data.keys()):\n",
    "            all_coordinates: list = data[ptrn]\n",
    "            \n",
    "            for local_cordinates in all_coordinates:\n",
    "                _X = np.append(_X, np.array([np.append(np.array(local_cordinates['x']), np.array(local_cordinates['y'])).tolist()]), axis=0)\n",
    "                _y = np.append(_y, 1) if ptrn == pattern_name else np.append(_y, 0)\n",
    "                random_value = np.append(random_value, np.random.rand()) # Генерация случайного числа от 0 до 1\n",
    "\n",
    "    # Сортировка по случайным величинам\n",
    "    return (np.array([x for _, x, _ in sorted(zip(random_value, _X, _y), key=lambda x: x[0])]),\n",
    "            np.array([y for _, _, y in sorted(zip(random_value, _X, _y), key=lambda x: x[0])]))\n",
    "\n",
    "X, y = parse(f'../dataset/e20d75f9635b4e909b22969600c03002.json', 'Sigmoid')\n",
    "test_data_X, test_data_y = parse(f'../dataset/f0486d0c97d6466890eb602317772a43.json', 'Sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Accuracy: 0.8378\n",
      "[Epoch 1] Accuracy: 0.8407857142857142\n",
      "[Epoch 2] Accuracy: 0.8407142857142857\n",
      "[Epoch 3] Accuracy: 0.8409571428571428\n",
      "[Epoch 4] Accuracy: 0.8402571428571428\n",
      "[ 5.62085176 13.15878992 -0.20572259 -8.86886863 -8.55005626 -5.23292386\n",
      "  6.16772313 -4.92258226 -9.65509509  0.32961015 11.78904726 10.2590788\n",
      "  1.6530362  -4.42634735]\n",
      "0.8569285714285715\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, lr=0.01, epochs=5):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Our fit function trains on the dataset X and tries to predict vector y,\n",
    "        Using the learning rate, it will modify it's weight vector to increase\n",
    "        it's accuracy in predictions.\n",
    "        It will iterate over the X dataset as defined by the epochs.\n",
    "        Args:\n",
    "            X: The input data (numpy array of shape [n_samples * m_features])\n",
    "            y: Class labels vector (numpy array of shape [n_samples])\n",
    "        \"\"\"\n",
    "        # a vector of floats between 0 and 1\n",
    "        weights = np.random.rand(X.shape[1],)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # list of predicted classes for our accuracy calculation\n",
    "            predicted = []\n",
    "            for i_index, sample in enumerate(X):\n",
    "                y_hat = self.predict(sample, weights)\n",
    "                predicted.append(y_hat)  # add our new prediction to the array\n",
    "                for j_index, feature in enumerate(weights):\n",
    "                    # update our weight values\n",
    "                    delta = self.lr * (y[i_index] - y_hat)\n",
    "                    delta = delta * sample[j_index-1]\n",
    "                    weights[j_index-1] = weights[j_index-1] + delta\n",
    "            print('[Epoch {ep}] Accuracy: {acc}'.format(\n",
    "                ep=epoch, acc=self._calculate_accuracy(y, predicted)\n",
    "            ))\n",
    "        self.weights = weights\n",
    "\n",
    "    def _calculate_accuracy(self, actual, predicted):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of predictions for this epoch.\n",
    "        Args:\n",
    "            actual: vector of actual class values (the y vector) [n_samples]\n",
    "            predicted: vector of predicted class values [n_samples]\n",
    "        \"\"\"\n",
    "        return sum(np.array(predicted) == np.array(actual)) / float(len(actual))\n",
    "\n",
    "    def predict(self, x, w):\n",
    "        \"\"\"\n",
    "        Create a binary prediction from an activation function on the data\n",
    "        sample and the weight vector.\n",
    "        Args:\n",
    "            x: vector of the data sample - shape [m_features]\n",
    "            w: vector of the weights - shape [m_features]\n",
    "        Returns:\n",
    "            0 or 1\n",
    "        \"\"\"\n",
    "        res = self._sum(x, w)\n",
    "        # print(res)\n",
    "        return 1 if res > 0.0 else 0.0\n",
    "\n",
    "    def _sum(self, x, w):\n",
    "        \"\"\"\n",
    "        Multiply our sample and weight vector elements then the sum of the\n",
    "        result.\n",
    "        Args:\n",
    "            x: vector of the data sample - shape [m_features]\n",
    "            w: vector of the weights - shape [m_features]\n",
    "        Returns:\n",
    "            Int of the sum of vector products\n",
    "        \"\"\"\n",
    "        return np.sum(np.dot(x, np.transpose(w)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Perceptron()\n",
    "    p.fit(X, y)\n",
    "    print(p.weights)\n",
    "    truth = 0\n",
    "    for i in range(len(test_data_X)):\n",
    "        prd = p.predict(test_data_X[i],p.weights)\n",
    "        # print(prd)\n",
    "        if prd == y[i]:\n",
    "            truth += 1\n",
    "    print(truth/len(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5102983151a502f0b3c21dd441eb79f35619ea9e057c95bc886ff9f2b76b13c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
